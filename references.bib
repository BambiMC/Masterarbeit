% Try to use the reference format from DBLP whenever possible. If a reference does not exist in the DBLP database, try to adopt a reference to their format. This is meaningful, as the DBLP entries are the most complete ones and consistent.



@online{heise2024,
  author  = {Heise Online},
  title   = {Angriffe auf KI-gestützte Software abwehren: Secure by Design},
  year    = {2024},
  url     = {https://www.heise.de/hintergrund/Angriffe-auf-KI-gestuetzte-Software-abwehren-Secure-by-Design-10286276.html},
  urldate = {2025-03-03}
}

@online{owasp2023,
  author  = {OWASP Foundation},
  title   = {OWASP Top 10 for Large Language Model Applications – 2023 (Version 1.1)},
  year    = {2023},
  url     = {https://owasp.org/www-project-top-10-for-large-language-model-applications/assets/PDF/OWASP-Top-10-for-LLMs-2023-v1_1.pdf},
  urldate = {2025-03-03}
}

@online{securityinsider2024,
  author  = {Security Insider},
  title   = {Real existierende Risiken von KI-Technologie: OWASP Top 10 LLM},
  year    = {2024},
  url     = {https://www.security-insider.de/real-existierende-risiken-von-ki-technologie-owasp-top-10-llm-a-aafa494b58b631dc82210eecee3dcf0f/?cflt=rdt},
  urldate = {2025-03-03}
}

@misc{EU_Regulation_2024_1689,
  title   = {{Regulation (EU) 2024/1689 of the European Parliament and of the Council of 13 June 2024 laying down harmonised rules on artificial intelligence and amending various Regulations and Directives (Artificial Intelligence Act)}},
  author  = {{European Union}},
  year    = {2024},
  url     = {https://eur-lex.europa.eu/legal-content/DE/TXT/?uri=CELEX:32024R1689},
  urldate = {2025-03-03}
}

@misc{DSGVO,
  title  = {Verordnung (EU) 2016/679 des Europäischen Parlaments und des Rates},
  author = {Europäische Union},
  year   = {2016},
  url    = {https://eur-lex.europa.eu/legal-content/DE/TXT/PDF/?uri=CELEX:32016R0679},
  note   = {2025-03-08}
}

@misc{Bayern_KI_Richtlinie,
  title  = {Rechtsgrundlagen für den Einsatz von Künstlicher Intelligenz in der Verwaltung},
  author = {Bayerisches Staatsministerium für Wissenschaft und Kunst},
  year   = {2024},
  url    = {https://web.archive.org/web/20241124035458/https://digitalverbund.bayern/wp-content/uploads/sites/12/2024/07/3.-Rechtsgrundlagen-fuer-den-Einsatz-von-KI.pdf}
}


% Verwandte Arbeiten



@misc{hassanin2024,
  title         = {A Comprehensive Overview of Large Language Models (LLMs) for Cyber Defences: Opportunities and Directions},
  author        = {Mohammed Hassanin and Nour Moustafa},
  year          = {2024},
  eprint        = {2405.14487},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CR},
  url           = {https://arxiv.org/abs/2405.14487}
}

@misc{xu2024,
  title         = {AutoAttacker: A Large Language Model Guided System to Implement Automatic Cyber-attacks},
  author        = {Jiacen Xu and Jack W. Stokes and Geoff McDonald and Xuesong Bai and David Marshall and Siyue Wang and Adith Swaminathan and Zhou Li},
  year          = {2024},
  eprint        = {2403.01038},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CR},
  url           = {https://arxiv.org/abs/2403.01038}
}

@misc{zhang2024,
  title         = {When LLMs Meet Cybersecurity: A Systematic Literature Review},
  author        = {Jie Zhang and Haoyu Bu and Hui Wen and Yongji Liu and Haiqiang Fei and Rongrong Xi and Lun Li and Yun Yang and Hongsong Zhu and Dan Meng},
  year          = {2024},
  eprint        = {2405.03644},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CR},
  url           = {https://arxiv.org/abs/2405.03644}
}

@misc{ferrag2025,
  title         = {Generative AI in Cybersecurity: A Comprehensive Review of LLM Applications and Vulnerabilities},
  author        = {Mohamed Amine Ferrag and Fatima Alwahedi and Ammar Battah and Bilel Cherif and Abdechakour Mechri and Norbert Tihanyi and Tamas Bisztray and Merouane Debbah},
  year          = {2025},
  eprint        = {2405.12750},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CR},
  url           = {https://arxiv.org/abs/2405.12750}
}

@misc{xu2024_overview,
  title         = {Large Language Models for Cyber Security: A Systematic Literature Review},
  author        = {Hanxiang Xu and Shenao Wang and Ningke Li and Kailong Wang and Yanjie Zhao and Kai Chen and Ting Yu and Yang Liu and Haoyu Wang},
  year          = {2024},
  eprint        = {2405.04760},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CR},
  url           = {https://arxiv.org/abs/2405.04760}
}

@article{yao2024,
  title    = {A survey on large language model (LLM) security and privacy: The Good, The Bad, and The Ugly},
  journal  = {High-Confidence Computing},
  volume   = {4},
  number   = {2},
  pages    = {100211},
  year     = {2024},
  issn     = {2667-2952},
  doi      = {https://doi.org/10.1016/j.hcc.2024.100211},
  url      = {https://www.sciencedirect.com/science/article/pii/S266729522400014X},
  author   = {Yifan Yao and Jinhao Duan and Kaidi Xu and Yuanfang Cai and Zhibo Sun and Yue Zhang},
  keywords = {Large Language Model (LLM), LLM security, LLM privacy, ChatGPT, LLM attacks, LLM vulnerabilities},
  abstract = {Large Language Models (LLMs), such as ChatGPT and Bard, have revolutionized natural language understanding and generation. They possess deep language comprehension, human-like text generation capabilities, contextual awareness, and robust problem-solving skills, making them invaluable in various domains (e.g., search engines, customer support, translation). In the meantime, LLMs have also gained traction in the security community, revealing security vulnerabilities and showcasing their potential in security-related tasks. This paper explores the intersection of LLMs with security and privacy. Specifically, we investigate how LLMs positively impact security and privacy, potential risks and threats associated with their use, and inherent vulnerabilities within LLMs. Through a comprehensive literature review, the paper categorizes the papers into “The Good” (beneficial LLM applications), “The Bad” (offensive applications), and “The Ugly” (vulnerabilities of LLMs and their defenses). We have some interesting findings. For example, LLMs have proven to enhance code security (code vulnerability detection) and data privacy (data confidentiality protection), outperforming traditional methods. However, they can also be harnessed for various attacks (particularly user-level attacks) due to their human-like reasoning abilities. We have identified areas that require further research efforts. For example, Research on model and parameter extraction attacks is limited and often theoretical, hindered by LLM parameter scale and confidentiality. Safe instruction tuning, a recent development, requires more exploration. We hope that our work can shed light on the LLMs’ potential to both bolster and jeopardize cybersecurity.}
}

@inproceedings{liu2024,
  author    = {Liu, Zefang},
  booktitle = {2024 12th International Symposium on Digital Forensics and Security (ISDFS)},
  title     = {A Review of Advancements and Applications of Pre-Trained Language Models in Cybersecurity},
  year      = {2024},
  volume    = {},
  number    = {},
  pages     = {1-10},
  keywords  = {Industries;Technological innovation;Ethics;Privacy;Reviews;Phishing;Telecommunication traffic;cybersecurity;pre-trained language models;large language models;natural language processing;domain-specific models},
  doi       = {10.1109/ISDFS60797.2024.10527236}
}
